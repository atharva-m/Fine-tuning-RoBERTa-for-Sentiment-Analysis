# ğŸ§  Hate Speech Detection using RoBERTa (Fine-Tuned)

![Python](https://img.shields.io/badge/Python-3.10-blue.svg)
![Transformers](https://img.shields.io/badge/HuggingFace-Transformers-yellow)
![License: CC0-1.0](https://img.shields.io/badge/License-CC0%201.0-lightgrey.svg)
![Status](https://img.shields.io/badge/status-production--ready-brightgreen)

This project demonstrates an end-to-end pipeline to fine-tune a `roberta-base` model for binary **hate speech detection**. It covers custom preprocessing, training, evaluation, inference, and visualization â€” optimized for high recall on sensitive inputs.

---

## ğŸš€ Quickstart

```bash
# 1. Clone and enter the project
$ git clone https://github.com/atharva-m/fine-tuning-roberta-for-sentiment-analysis.git
$ cd fine-tuning-roberta-for-sentiment-analysis

# 2. Setup virtual environment
$ python -m venv .venv && source .venv/bin/activate  

# 3. Install dependencies
$ pip install -r requirements.txt

# 4. Train model
$ python src/train.py --config config.yaml

# 5. Evaluate on test set
$ python src/evaluate.py --config config.yaml

# 6. Predict a single text
$ python src/predict.py --checkpoint models/best_model --text "Some tweet here"

# 7. Batch prediction
$ python src/predict.py --checkpoint models/best_model --input data/test.csv --output predictions.csv
```

---

## ğŸ“Š Key Features

| Stage           | Description                                                           |
|----------------|-----------------------------------------------------------------------|
| âš™ Preprocessing | Emoji removal, hashtag cleaning, punctuation stripping, lowercasing  |
| ğŸ§  Model        | `roberta-base`, fine-tuned for 5 epochs using `Trainer` API          |
| ğŸ¯ Objective     | Binary classification: Hate Speech (1) vs Not Hate Speech (0)        |
| ğŸ“ˆ Metrics       | Accuracy: **97.07%**, Precision: 96.95%, F1: 96.99%, Recall: 97.07%  |
| ğŸ“Š Confusion Matrix | Exported to `reports/confusion_matrix.png` for visual inspection |
| ğŸ’¾ Inference     | Script supports both single-sentence and batch CSV classification    |

---

## ğŸ—‚ Project Structure

```
â”œâ”€â”€ data/              # Raw and preprocessed CSV files
â”œâ”€â”€ models/            # Final saved transformer model and tokenizer
â”œâ”€â”€ reports/           # Evaluation metrics and confusion matrix
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py       # Training and fine-tuning script
â”‚   â”œâ”€â”€ evaluate.py    # Test evaluation and confusion matrix
â”‚   â””â”€â”€ predict.py     # CLI inference for single/batch mode
â”œâ”€â”€ config.yaml        # Model config: learning rate, batch size, epochs
â”œâ”€â”€ requirements.txt   # pip dependencies
â””â”€â”€ predictions.csv    # Output from batch prediction
```

---

## ğŸ§  Model Training

- Model: `roberta-base` from Hugging Face
- Loss: CrossEntropy
- Optimizer: AdamW
- Scheduler: Linear with warmup
- Max Sequence Length: 256
- Batch Size: 50
- Epochs: 5
- Device: CUDA (if available)

---

## ğŸ”¬ Evaluation Metrics (from `evaluate.py`)

| Metric     | Score     |
|------------|-----------|
| Accuracy   | 97.07%    |
| Precision  | 96.95%    |
| Recall     | 97.07%    |
| F1-Score   | 96.99%    |
| Confusion Matrix | âœ… See `reports/confusion_matrix.png` |

---

## ğŸ“ License

This project is licensed under the **Creative Commons Zero v1.0 Universal (CC0 1.0)** â€” you may use, modify, and distribute freely without attribution.

---

### Contact

Atharva Mokashi Â· atharvamokashi01@gmail.com Â· [LinkedIn](https://www.linkedin.com/in/atharva-m)
